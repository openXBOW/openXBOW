h:Print this help\n

# IO
i:Name/Path of an input (ARFF or CSV) file p containing feature vectors over time\n\
  The first feature must be a string or number which specifies all feature vectors which belong to one analysis window/instance.
attributes:An optional string, specifying all input attributes (mandatory if multiple label): \n\
           n=name, t=time stamp, 0=text feature, [1-9]=numeric feature, c=class label/numeric label, r=remove attribute\n\
           Using different numbers for numeric features will create a separate codebook and bag for all features belonging to the same index.
o:Name / Path of an output ARFF, CSV or LibSVM file p containing the bag-of-features representation.\n\
  The file format depends on the given file ending (*.arff, *.csv or *.libsvm).
writeName:Output the id string/number in the output file (only ARFF & CSV).
writeTimeStamp:Output the time stamp in the output file (only ARFF & CSV).
l:CSV file p with the class labels for each analysis window/instance.\n\
  Both nominal and numeric classes are supported. Format:\n\
  1st line: name (according to the input file); label1; label2; ...\n\
  2nd line: 'file_1.wav'; class1; ...\n\
            [and so on]\n

# Preprocessing options
t:Segment the input files with a windows size (segment width) of p1 seconds and a hop size (shift) of p2 seconds\n\
  If this option is used, the second column of the input file must be a time index (in seconds) of the current frame and \n\
  the (optional) labels file must have three columns (name; time; label). The time instances where labels are given must \n\
  fit with the given parameters.\n
e:Remove all feature vectors from the input, where the activity (or energy) is below p2. Index p1 specifies the index of the activity feature - starting with 1.
standardizeInput:Standardize all numeric input features. The standardization parameters are written to the codebook file and then taken to standardize test data.
normalizeInput:Normalize all numeric input features (min->max is normalized to 0->1). The normalization parameters are written to the codebook file and then taken to normalize test data.

# Codebook (only numeric features)
size:Set the (initial) size p of the codebook. (default: size=500)
c:Method of creating the codebook:\n\
  p=random (default): Generate the codebook by random sampling of the input feature vectors.\n\
  p=random++: Generate the codebook by random sampling of the input feature vectors with weighting similiar to initialization of kmeans++.\n\
  p=kmeans: Employ kmeans clustering (Lloyd's algorithm).\n\
  p=kmeans++: Employ kmeans++ clustering (Lloyd's algorithm).
supervised:Generate a codebook for each class separately, first, then merge all openxbow.codebooks. (Not available for numeric labels.)
numTrain:Randomly choose p feature vectors from the input data for the creation of the codebook (should not be used for random sampling).
svq:If >= 1, split vector quantization (SVQ) is used. The feature vectors are split into p1 sub-vectors. Codebooks are created for each sub-vector.\n\
  Then, a final codebook and bag is created from the assigned indexes of the sub-vectors. p2 specifies the size of the sub-openxbow.codebooks.\n

b:Load codebook p (do not create one).
B:Save the created codebook as a file p.\n

# Assignment (only numeric)
a:When creating the bag-of-features, assign each feature vector p vectors from the quantized vectors in the codebook. (default: a=1)
gaussian:Soft assignment using Gaussian encoding with standard deviation p.\n

# Assignment (only text)
minTermFreq:Gives a minimum threshold for the number of occurrences of each word/n-gram to be considered for codebook generation (default: minTermFreq=1)
maxTermFreq:Gives a maximum threshold for the number of occurrences of each word/n-gram to be considered for codebook generation (default: minTermFreq=0(inf))
stopChar:Specifies characters which are removed from all input instances (default: .,;:()?!* )
nGram:N-gram (default: nGram=1)
nCharGram:N-character-gram (default: nCharGram=0)\n

# Assignment general
log:Logarithmic term weighting 'lg(TF+1)' of the term frequency.\n\
    This parameter is transmitted in the codebook file. If a codebook is loaded the term weighting specified therein is taken.
idf:Inverse document frequency transform: Multiply the term frequency (TF) with the logarithm of the ratio of the \n\
    total number of instances and the number of instances where the respective word is present.\n\
    This parameter and the idf weights are transmitted in the codebook file.\n\
    If a codebook is loaded the term weighting specified therein is taken.
norm:Normalize the bag-of-features (3 options of normalization).\n\
     p=1: Divides the term frequencies (TF) by the number of input frames.\n\
     p=2: Divides the TF by the sum of all TFs.\n\
     p=3: Divides the TF by a factor so that the resulting Euclidean length is 1.
